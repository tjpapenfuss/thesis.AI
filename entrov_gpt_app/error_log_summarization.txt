Invalid request error retrieving: https://aws.amazon.com/cn/partners/success/opg/Here is the error:
Traceback (most recent call last):
  File "/Users/tannerpapenfuss/thesis.AI/entrov_gpt_app/workflow_manager.py", line 51, in <module>
    json_data["Summary"] = doc_summarization.summarize_doc(document=page_text)
  File "/Users/tannerpapenfuss/thesis.AI/entrov_gpt_app/doc_summarization.py", line 47, in summarize_doc
    return map_chain.run(texts)
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/base.py", line 213, in run
    return self(args[0])[self.output_keys[0]]
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/base.py", line 116, in __call__
    raise e
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/base.py", line 113, in __call__
    outputs = self._call(inputs)
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py", line 75, in _call
    output, extra_return_dict = self.combine_docs(docs, **other_keys)
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py", line 82, in combine_docs
    return self.llm_chain.predict(**inputs), {}
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py", line 151, in predict
    return self(kwargs)[self.output_key]
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/base.py", line 116, in __call__
    raise e
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/base.py", line 113, in __call__
    outputs = self._call(inputs)
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py", line 57, in _call
    return self.apply([inputs])[0]
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py", line 118, in apply
    response = self.generate(input_list)
  File "/usr/local/lib/python3.10/site-packages/langchain/chains/llm.py", line 62, in generate
    return self.llm.generate_prompt(prompts, stop)
  File "/usr/local/lib/python3.10/site-packages/langchain/chat_models/base.py", line 82, in generate_prompt
    raise e
  File "/usr/local/lib/python3.10/site-packages/langchain/chat_models/base.py", line 79, in generate_prompt
    output = self.generate(prompt_messages, stop=stop)
  File "/usr/local/lib/python3.10/site-packages/langchain/chat_models/base.py", line 54, in generate
    results = [self._generate(m, stop=stop) for m in messages]
  File "/usr/local/lib/python3.10/site-packages/langchain/chat_models/base.py", line 54, in <listcomp>
    results = [self._generate(m, stop=stop) for m in messages]
  File "/usr/local/lib/python3.10/site-packages/langchain/chat_models/openai.py", line 266, in _generate
    response = self.completion_with_retry(messages=message_dicts, **params)
  File "/usr/local/lib/python3.10/site-packages/langchain/chat_models/openai.py", line 228, in completion_with_retry
    return _completion_with_retry(**kwargs)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 289, in wrapped_f
    return self(f, *args, **kw)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 379, in __call__
    do = self.iter(retry_state=retry_state)
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 314, in iter
    return fut.result()
  File "/usr/local/Cellar/python@3.10/3.10.7/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py", line 451, in result
    return self.__get_result()
  File "/usr/local/Cellar/python@3.10/3.10.7/Frameworks/Python.framework/Versions/3.10/lib/python3.10/concurrent/futures/_base.py", line 403, in __get_result
    raise self._exception
  File "/usr/local/lib/python3.10/site-packages/tenacity/__init__.py", line 382, in __call__
    result = fn(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/langchain/chat_models/openai.py", line 226, in _completion_with_retry
    return self.client.create(**kwargs)
  File "/usr/local/lib/python3.10/site-packages/openai/api_resources/chat_completion.py", line 25, in create
    return super().create(*args, **kwargs)
  File "/usr/local/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py", line 153, in create
    response, _, api_key = requestor.request(
  File "/usr/local/lib/python3.10/site-packages/openai/api_requestor.py", line 226, in request
    resp, got_stream = self._interpret_response(result, stream)
  File "/usr/local/lib/python3.10/site-packages/openai/api_requestor.py", line 620, in _interpret_response
    self._interpret_response_line(
  File "/usr/local/lib/python3.10/site-packages/openai/api_requestor.py", line 683, in _interpret_response_line
    raise self.handle_error_response(
openai.error.InvalidRequestError: This model's maximum context length is 4097 tokens. However, your messages resulted in 4694 tokens. Please reduce the length of the messages.

